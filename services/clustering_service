from sentence_transformers import SentenceTransformer
from sklearn.cluster import DBSCAN
from repository.incident_repo import IncidentRepository
from google.cloud import firestore
from datetime import datetime
import numpy as np

class ClusteringService:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.incident_repo = IncidentRepository()
        self.db = firestore.Client()
        self.similarity_threshold = 0.7  

    def cluster_reports(self):
        reports_stream = self.incident_repo.collection.stream()
        reports = [r.to_dict() for r in reports_stream]
        if not reports:
            return []

        descriptions = [r["description"] for r in reports]
        embeddings = self.model.encode(descriptions, convert_to_numpy=True)

        from sklearn.metrics.pairwise import cosine_distances
        dist_matrix = cosine_distances(embeddings)

        clustering = DBSCAN(eps=1-self.similarity_threshold, min_samples=1, metric='precomputed')
        labels = clustering.fit_predict(dist_matrix)

        for report, cluster_id in zip(reports, labels):
            report_id = report["id"]
            self.incident_repo.collection.document(report_id).update({"cluster_id": int(cluster_id)})

        clusters = {}
        for report, cluster_id in zip(reports, labels):
            cluster_id = int(cluster_id)
            if cluster_id not in clusters:
                clusters[cluster_id] = {
                    "cluster_id": cluster_id,
                    "report_ids": [],
                    "category": report.get("category", "Other"),
                    "created_at": datetime.utcnow()
                }
            clusters[cluster_id]["report_ids"].append(report["id"])

        for cluster in clusters.values():
            self.db.collection("clusters").document(str(cluster["cluster_id"])).set(cluster)

        return clusters
